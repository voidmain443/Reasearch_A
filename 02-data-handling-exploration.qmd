---
title : " 파이썬을 이용한 데이터 핸들링 및 탐색: Pandas DataFrame 기초"

format: 
    html: 
        code-fold: false
jupyter: python3
---
::: callout-note
## 📌 핵심 요약

Pandas DataFrame은 파이썬에서 표 형태의 데이터를 다루는 데 필수적인 자료 구조입니다. 이 절에서는 DataFrame 생성, 정보 확인, 인덱싱, 슬라이싱, 데이터 조작 등 기본적인 사용법을 학습합니다.
:::

##   2.1 파이썬을 이용한 데이터 핸들링 및 탐색: Pandas DataFrame 기초

사회과학 연구에서 데이터를 수집하고 분석하는 과정은 종종 복잡하고 방대한 양의 데이터를 다루는 것을 포함합니다. 파이썬의 Pandas 라이브러리는 이러한 데이터를 효율적으로 처리하고 분석하는 데 필수적인 도구입니다. 본 절에서는 Pandas의 핵심 자료 구조인 DataFrame을 중심으로, 데이터 핸들링 및 탐색의 기초를 다룹니다.

* **(시각 자료 예시:** Pandas DataFrame의 구조를 보여주는 그림. 행과 열, 열 이름, 인덱스 등을 명확하게 표시한 표 형태의 그림)

###   2.1.1 Pandas DataFrame의 개념

Pandas DataFrame은 2차원 테이블 형태의 데이터 구조로서, 행(Row)과 열(Column)로 구성됩니다. 각 열은 서로 다른 데이터 유형(숫자, 문자열, 날짜 등)을 가질 수 있으며, 스프레드시트나 SQL 테이블과 유사한 구조를 갖습니다.

DataFrame은 다음과 같은 특징을 가집니다.

* **다양한 데이터 유형 처리:** 각 열은 서로 다른 데이터 유형을 가질 수 있습니다.
* **레이블 기반 인덱싱:** 행과 열에 레이블(이름)을 사용하여 데이터에 접근할 수 있습니다.
* **결측치 처리:** 결측치(Missing Data)를 효율적으로 처리하는 기능을 제공합니다.
* **데이터 조작 기능:** 데이터 필터링, 정렬, 그룹화, 병합 등 다양한 데이터 조작 기능을 제공합니다.

###   2.1.2 DataFrame 생성

DataFrame은 다양한 방법으로 생성할 수 있습니다.

* **(시각 자료 예시:** DataFrame 생성 방법을 보여주는 그림. 리스트, 딕셔너리, CSV 파일 등 다양한 입력 소스로부터 DataFrame을 생성하는 과정을 간략하게 보여주는 그림)

* **리스트(List)로부터 생성:**

    * 2차원 리스트를 사용하여 DataFrame을 생성할 수 있습니다.
    * 각 내부 리스트는 DataFrame의 한 행을 나타냅니다.

```{python}
    import pandas as pd

    data = [['Alice', 25, 'Female'], ['Bob', 30, 'Male'], ['Charlie', 28, 'Male']]
    df = pd.DataFrame(data, columns=['Name', 'Age', 'Gender'])
    print(df)
```

* **딕셔너리(Dictionary)로부터 생성:**

    * 딕셔너리를 사용하여 DataFrame을 생성할 수 있습니다.
    * 딕셔너리의 키(Key)는 DataFrame의 열 이름이 되고, 값(Value)은 열 데이터가 됩니다.

```{python}
    data = {'Name': ['Alice', 'Bob', 'Charlie'], 'Age': [25, 30, 28], 'Gender': ['Female', 'Male', 'Male']}
    df = pd.DataFrame(data)
    print(df)
    df.to_csv('data.csv', index=False) # DataFrame을 data.csv 파일로 저장 (index 제외)
```

* **CSV 파일로부터 생성:**

    * CSV(Comma Separated Values) 파일로부터 DataFrame을 생성할 수 있습니다.
    * `pd.read_csv()` 함수를 사용합니다.

```{python}
    df = pd.read_csv('data.csv') # data.csv 파일로부터 DataFrame 생성
    print(df)
```

|   생성 방법   |                       설명                       |                       예시                       |
| :-----------: | :--------------------------------------------: | :------------------------------------------------: |
|   리스트 생성   |           2차원 리스트를 사용하여 생성           | `pd.DataFrame(data, columns=['Name', 'Age', 'Gender'])` |
|   딕셔너리 생성   |           딕셔너리를 사용하여 생성           |                 `pd.DataFrame(data)`                 |
|   CSV 파일 생성   |           CSV 파일로부터 생성           |                   `pd.read_csv('data.csv')`                   |

###   2.1.3 DataFrame 정보 확인

DataFrame의 구조, 데이터 유형, 결측치 정보 등을 확인하는 것은 데이터 분석의 첫 단계입니다.

* **(시각 자료 예시:** DataFrame 정보 확인 방법을 보여주는 그림. `head()`, `info()`, `describe()` 등의 함수를 사용하여 DataFrame의 일부 데이터, 구조, 통계량 등을 확인하는 과정을 간략하게 보여주는 그림)

* **`head()`:**

    * DataFrame의 처음 몇 행을 표시합니다.
    * 기본적으로 처음 5행을 표시하며, 괄호 안에 숫자를 넣어 표시할 행 수를 지정할 수 있습니다.

```{python}
    print(df.head()) # 처음 5행 표시
    print(df.head(10)) # 처음 10행 표시
```

* **`info()`:**

    * DataFrame의 구조, 열 이름, 데이터 유형, 결측치 개수 등을 요약하여 표시합니다.

```{python}
    print(df.info())
```

* **`describe()`:**

    * 수치형 열에 대한 기술 통계량(평균, 표준편차, 최소값, 최대값, 사분위수 등)을 요약하여 표시합니다.

```{python}
    print(df.describe())
```

|   확인 함수   |                       설명                       |                       예시                       |
| :-----------: | :--------------------------------------------: | :------------------------------------------------: |
|    `head()`   |               DataFrame의 처음 몇 행 표시               |                   `df.head()`                   |
|    `info()`   |            DataFrame의 구조, 데이터 유형, 결측치 정보 확인            |                   `df.info()`                   |
|  `describe()`  |               수치형 열의 기술 통계량 요약               |                 `df.describe()`                 |

###   2.1.4 DataFrame 인덱싱 및 슬라이싱

DataFrame에서 특정 데이터에 접근하거나, 특정 행 또는 열을 선택하는 것을 인덱싱(Indexing) 및 슬라이싱(Slicing)이라고 합니다.

* **(시각 자료 예시:** DataFrame 인덱싱 및 슬라이싱 방법을 보여주는 그림. `[]`, `loc[]`, `iloc[]` 등을 사용하여 특정 데이터에 접근하거나, 행/열을 선택하는 과정을 간략하게 보여주는 그림)

* **`[]` 연산자:**

    * 열 이름을 사용하여 열을 선택합니다.

```{python}
    print(df['Name']) # 'Name' 열 선택
    print(df[['Name', 'Age']]) # 'Name'과 'Age' 열 선택
```

* **`loc[]` 메서드:**

    * 행과 열의 레이블을 사용하여 데이터에 접근합니다.

```{python}
    print(df.loc[0]) # 0번 행 선택
    print(df.loc[0:2, 'Name']) # 0번부터 2번 행까지, 'Name' 열 선택
    print(df.loc[:, ['Name', 'Age']]) # 모든 행, 'Name'과 'Age' 열 선택
```

* **`iloc[]` 메서드:**

    * 행과 열의 정수 인덱스를 사용하여 데이터에 접근합니다.

```{python}
    print(df.iloc[0]) # 0번 행 선택
    print(df.iloc[0:2, 0]) # 0번부터 2번 행까지, 0번 열 선택
    print(df.iloc[:, [0, 1]]) # 모든 행, 0번과 1번 열 선택
```

|   인덱싱/슬라이싱 방법   |                       설명                       |                       예시                       |
| :-------------------: | :--------------------------------------------: | :------------------------------------------------: |
|        `[]`        |                   열 이름으로 열 선택                   |                 `df['Name']`                 |
|       `loc[]`       |               행/열 레이블로 데이터 접근               |               `df.loc[0:2, 'Name']`               |
|       `iloc[]`       |               행/열 정수 인덱스로 데이터 접근               |               `df.iloc[:, [0, 1]]`               |

###   2.1.5 DataFrame 데이터 조작

DataFrame은 다양한 데이터 조작 기능을 제공합니다.

* **(시각 자료 예시:** DataFrame 데이터 조작 방법을 보여주는 그림. 새로운 열 추가, 열 삭제, 데이터 필터링, 정렬 등을 수행하는 과정을 간략하게 보여주는 그림)

* **새로운 열 추가:**

```{python}
    df['Salary'] = [50000, 60000, 55000] # 'Salary' 열 추가
    df['Age_Plus_10'] = df['Age'] + 10 # 'Age' 열을 이용하여 'Age_Plus_10' 열 추가
```


* **데이터 필터링:**

```{python}
    df_filtered = df[df['Age'] > 28] # 'Age' 열이 28보다 큰 행만 선택
    df_filtered = df[(df['Age'] > 25) & (df['Gender'] == 'Male')] # 'Age' 열이 25보다 크고 'Gender' 열이 'Male'인 행만 선택
```

* **데이터 정렬:**

```{python}
    df_sorted = df.sort_values(by='Age', ascending=True) # 'Age' 열을 기준으로 오름차순 정렬
    df_sorted = df.sort_values(by=['Gender', 'Age'], ascending=[True, False]) # 'Gender' 열을 기준으로 오름차순 정렬 후, 'Age' 열을 기준으로 내림차순 정렬
```

|   조작 방법   |                       설명                       |                       예시                       |
| :-----------: | :--------------------------------------------: | :------------------------------------------------: |
|   새로운 열 추가   |                   DataFrame에 새로운 열 추가                   |           `df['Salary'] = [50000, 60000, 55000]`           |
|     열 삭제     |                     DataFrame에서 열 삭제                     |               `df = df.drop(columns=['Gender'])`               |
|   데이터 필터링   |                 특정 조건을 만족하는 행만 선택                 |                `df[df['Age'] > 28]`                |
|   데이터 정렬   |                   DataFrame의 행을 특정 열을 기준으로 정렬                   |             `df.sort_values(by='Age')`             |

* **열 삭제:**

```{python}
    df = df.drop(columns=['Gender']) # 'Gender' 열 삭제
```


###   2.1.6 DataFrame 활용의 중요성

Pandas DataFrame은 사회과학 연구 데이터를 효율적으로 관리하고 분석하는 데 필수적인 도구입니다. DataFrame을 통해 데이터를 구조화하고, 다양한 데이터 조작 기능을 활용함으로써, 연구자는 데이터 분석 과정을 체계적으로 수행하고, 연구 결과의 신뢰성을 높일 수 있습니다.



##   2.2 파이썬을 이용한 데이터 핸들링 및 탐색: 데이터 전처리

사회과학 연구에서 수집된 데이터는 종종 결측치, 이상치, 불일치 등 다양한 문제점을 포함하고 있습니다. 이러한 데이터 문제를 해결하고 분석에 적합한 형태로 데이터를 변환하는 과정을 **데이터 전처리(Data Preprocessing)**라고 합니다. 본 절에서는 파이썬 Pandas 라이브러리를 이용하여 데이터 전처리를 수행하는 주요 방법에 대해 설명합니다.

* **(시각 자료 예시:** 데이터 전처리 과정을 보여주는 흐름도. 결측치 처리, 이상치 처리, 변수 변환 등의 단계를 포함하는 그림)

###   2.2.1 결측치 처리

**결측치(Missing Data)**는 데이터에 값이 존재하지 않는 경우를 의미합니다. 결측치는 데이터 분석 결과의 왜곡을 초래할 수 있으므로, 적절한 방법으로 처리해야 합니다.

* **(시각 자료 예시:** 결측치 처리 방법을 비교하는 표. 삭제, 대체, 예측 등 다양한 방법의 장단점을 비교하는 표)

    * **결측치 확인:**
        * `isnull()` 또는 `isna()` 함수를 사용하여 결측치를 확인할 수 있습니다.
        * `sum()` 함수와 함께 사용하여 결측치의 개수를 확인할 수 있습니다.

```{python}
    import pandas as pd

    # 예시 DataFrame 생성
    data = {'A': [1, 2, None, 4, 5], 'B': [6, None, 8, 9, 10], 'C': ['a', 'b', 'c', None, 'e']}
    df = pd.DataFrame(data)

    print(df.isnull())
    print(df.isnull().sum())
```

    * **결측치 삭제:**
        * `dropna()` 함수를 사용하여 결측치를 포함하는 행 또는 열을 삭제할 수 있습니다.
        * `axis` 매개변수를 사용하여 행(0) 또는 열(1) 삭제를 지정할 수 있습니다.
        * `how` 매개변수를 사용하여 모든 값이 결측치인 경우(`'all'`) 또는 하나라도 결측치가 있는 경우(`'any'`)를 지정할 수 있습니다.

```{python}
    df_dropped_row = df.dropna(axis=0)
    df_dropped_col = df.dropna(axis=1)
    df_dropped_all = df.dropna(axis=0, how='all')
    print(df_dropped_row)
    print(df_dropped_col)
    print(df_dropped_all)
```

    * **결측치 대체:**
        * `fillna()` 함수를 사용하여 결측치를 특정 값으로 대체할 수 있습니다.
        * `value` 매개변수를 사용하여 대체할 값을 지정할 수 있습니다.
        * `method` 매개변수를 사용하여 이전 값(`'ffill'`) 또는 다음 값(`'bfill'`)으로 대체할 수 있습니다.
        * `mean()`, `median()`, `mode()` 등 통계 함수를 사용하여 대체값을 계산할 수 있습니다.

```{python}
    df_filled_0 = df.fillna(0)
    df_filled_mean = df.fillna(df.mean(numeric_only=True))
    df_filled_ffill = df.fillna(method='ffill')
    print(df_filled_0)
    print(df_filled_mean)
    print(df_filled_ffill)
```

    |   처리 방법   |                       설명                       |                       예시                       |
    | :-----------: | :--------------------------------------------: | :------------------------------------------------: |
    |   결측치 확인   |               `isnull()`, `isna()`               |                   `df.isnull()`                   |
    |   결측치 삭제   |                  `dropna()`                  |                 `df.dropna()`                 |
    |   결측치 대체   |                  `fillna()`                  |                 `df.fillna(0)`                 |

###   2.2.2 이상치 처리

**이상치(Outlier)**는 다른 데이터와 확연히 구분되는 극단적인 값을 의미합니다. 이상치는 데이터 분석 결과의 왜곡을 초래할 수 있으므로, 탐지하고 적절하게 처리해야 합니다.

* **(시각 자료 예시:** 이상치 탐지 방법을 보여주는 그림. 상자 그림, 산점도 등을 사용하여 이상치를 시각적으로 탐지하는 그림)

    * **이상치 탐지:**
        * **시각적 방법:** 상자 그림(`boxplot()`), 산점도(`scatter()`) 등을 사용하여 이상치를 시각적으로 탐지할 수 있습니다.

```{python}
    import matplotlib.pyplot as plt
    import seaborn as sns

    sns.boxplot(x=df['B'])
    plt.show()

    sns.scatterplot(x=df.index, y=df['B'])
    plt.show()
```

        * **통계적 방법:** Z-점수, 사분위 범위(Interquartile Range, IQR) 등을 사용하여 이상치를 탐지할 수 있습니다.

```{python}
    Q1 = df['B'].quantile(0.25)
    Q3 = df['B'].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = df[(df['B'] < lower_bound) | (df['B'] > upper_bound)]
    print(outliers)
```

    * **이상치 처리:**
        * **삭제:** 이상치를 포함하는 행 또는 열을 삭제합니다.
        * **대체:** 이상치를 특정 값(평균, 중앙값, 최빈값 등)으로 대체하거나, 상한/하한 값으로 제한합니다.
        * **변환:** 로그 변환, 제곱근 변환 등을 통해 이상치의 영향을 줄입니다.

```{python}
    df_clipped = df.copy()
    df_clipped['B'] = df_clipped['B'].clip(lower=lower_bound, upper=upper_bound)
    print(df_clipped)
```

    |   처리 방법   |                       설명                       |                       예시                       |
    | :-----------: | :--------------------------------------------: | :------------------------------------------------: |
    |   이상치 탐지   |         시각적/통계적 방법으로 이상치 확인         |                   상자 그림, IQR                   |
    |     삭제     |                 이상치를 포함하는 행/열 삭제                 |                 `df.dropna()`                 |
    |     대체     |            이상치를 특정 값으로 대체/제한            |                   `df.fillna()`                   |
    |     변환     |                로그 변환, 제곱근 변환 등                |                  `np.log()`                  |



###   2.2.3 변수 변환

**변수 변환(Variable Transformation)**은 변수의 형태나 분포를 변경하여 데이터 분석의 효율성을 높이거나, 특정 분석 방법에 적합하도록 데이터를 만드는 과정입니다.

* **(시각 자료 예시:** 변수 변환 방법을 보여주는 그림. 로그 변환, 표준화, 정규화 등을 통해 변수의 분포나 척도를 변경하는 그림)

    * **척도 변환(Scaling):**
        * 변수의 척도를 변경하여 서로 다른 변수 간의 비교를 용이하게 하거나, 특정 알고리즘의 성능을 향상시킵니다.
        * **표준화(Standardization):** 변수의 평균을 0, 표준편차를 1로 변환합니다.

        $Z = \frac{X - \mu}{\sigma}$

```{python}
    from sklearn.preprocessing import StandardScaler

    scaler = StandardScaler()
    df['A_scaled'] = scaler.fit_transform(df[['A']])
    print(df[['A', 'A_scaled']].head())
```

        * **정규화(Normalization):** 변수의 값을 0과 1 사이의 범위로 변환합니다.

        $X_{scaled} = \frac{X - X_{min}}{X_{max} - X_{min}}$

```{python}
    from sklearn.preprocessing import MinMaxScaler

    scaler = MinMaxScaler()
    df['B_scaled'] = scaler.fit_transform(df[['B']])
    print(df[['B', 'B_scaled']].head())
```

    * **분포 변환(Distribution Transformation):**
        * 변수의 분포를 변경하여 특정 분석 방법에 적합하도록 만듭니다.
        * **로그 변환(Log Transformation):** 오른쪽으로 꼬리가 긴 분포(Right-Skewed Distribution)를 정규 분포에 가깝게 만듭니다.

```{python}
    import numpy as np

    df_log = df.copy()
    df_log['A_log'] = np.log(df_log['A'][df_log['A'] > 0]) # 0 또는 음수 값을 제외하고 로그 변환
    print(df_log[['A', 'A_log']].head())
```

        * **제곱근 변환(Square Root Transformation):** 로그 변환과 유사한 효과를 가지며, 0을 포함하는 데이터에 적용할 수 있습니다.

```{python}
    df_sqrt = df.copy()
    df_sqrt['B_sqrt'] = np.sqrt(df_sqrt['B'][df_sqrt['B'] >= 0]) # 음수 값을 제외하고 제곱근 변환
    print(df_sqrt[['B', 'B_sqrt']].head())
```

    * **범주형 변수 처리:**
        * 범주형 변수를 분석에 활용하기 위해 수치형 변수로 변환합니다.
        * **더미 변수화(Dummy Variable Encoding):** 각 범주를 0 또는 1로 표현하는 새로운 변수를 생성합니다.

```{python}
    df_encoded = pd.get_dummies(df, columns=['C'], drop_first=True) # 'C' 열을 더미 변수화 (첫 번째 범주 제외)
    print(df_encoded.head())
```

        * **원-핫 인코딩(One-Hot Encoding):** 더미 변수화와 유사하지만, 첫 번째 범주를 제외하지 않습니다.

```{python}
    df_onehot = pd.get_dummies(df, columns=['C']) # 'C' 열을 원-핫 인코딩
    print(df_onehot.head())
```

    |   변환 방법   |                       설명                       |                       예시                       |
    | :-----------: | :--------------------------------------------: | :------------------------------------------------: |
    |   척도 변환   |               변수의 척도를 변경               |         표준화, 정규화         |
    |   분포 변환   |               변수의 분포를 변경               |         로그 변환, 제곱근 변환         |
    | 범주형 변수 처리 |             범주형 변수를 수치형으로 변환             | 더미 변수화, 원-핫 인코딩 |

###   2.2.4 데이터 전처리 과정의 중요성

데이터 전처리는 데이터 분석의 정확성과 신뢰성을 높이는 데 필수적인 과정입니다. 적절한 전처리 과정을 통해 데이터의 품질을 향상시키고, 분석에 적합한 형태로 데이터를 변환함으로써, 연구자는 더욱 정확하고 의미 있는 결과를 얻을 수 있습니다.



## 2.3 기술 통계 분석 {#sec-descriptive-stats}

데이터 전처리를 통해 데이터를 분석에 적합한 형태로 정제했다면, 다음 단계는 데이터의 기본적인 특성을 파악하는 것입니다. **기술 통계 분석(Descriptive Statistics Analysis)**은 수집된 데이터를 요약하고 설명하여 데이터가 가진 정보를 효과적으로 전달하는 통계적 방법입니다. 이는 데이터의 중심 경향성(Central Tendency), 산포도(Dispersion), 분포 형태(Distribution Shape) 등을 파악하여 데이터에 대한 깊이 있는 이해를 돕고, 이어질 추론 통계 분석의 기초를 마련합니다.

본 절에서는 파이썬 Pandas 라이브러리를 활용하여 주요 기술 통계량을 계산하고 해석하는 방법을 학습합니다.

::: callout-note
## 📌 핵심 요약

기술 통계 분석은 데이터의 기본적인 특성을 요약하고 설명하는 과정입니다. Pandas를 이용하여 평균, 중앙값, 최빈값 등 중심 경향성 지표와 분산, 표준편차, 범위, 사분위수 등 산포도 지표를 계산하고 해석하는 방법을 배웁니다. 또한, 범주형 데이터의 빈도 분석 방법과 `.describe()` 함수를 활용한 요약 통계량 확인 방법을 익힙니다.
:::

*(시각 자료 예시: 기술 통계 분석의 주요 목표(중심 경향성, 산포도, 분포 형태 파악)를 보여주는 다이어그램)*

### 가상 데이터 생성

기술 통계 분석 실습을 위해 가상의 설문조사 응답 데이터를 담은 Pandas DataFrame을 생성해 보겠습니다. 이 데이터는 'ID', 'Age', 'Gender', 'EducationLevel', 'SatisfactionScore', 'Income' 열을 포함합니다.

```{python}
import pandas as pd
import numpy as np

# 가상 데이터 생성
data = {
    'ID': range(1, 11),
    'Age': [25, 30, 28, 35, 42, 29, 31, 45, 22, 38],
    'Gender': ['Female', 'Male', 'Male', 'Female', 'Male', 'Female', 'Male', 'Female', 'Female', 'Male'],
    'EducationLevel': ['Bachelor', 'Master', 'Bachelor', 'PhD', 'Master', 'Bachelor', 'Master', 'PhD', 'High School', 'Master'],
    'SatisfactionScore': [7, 8, 6, 9, 7, np.nan, 8, 10, 5, 7], # 결측치(NaN) 포함
    'Income': [5000, 6000, 5500, 7500, 8000, 5200, 6100, 9000, 4000, 7000]
}
df_survey = pd.DataFrame(data)

print("가상 설문조사 데이터:")
print(df_survey.head()) # 데이터 일부 확인
print("\n데이터 정보 요약:")
print(df_survey.info()) # 데이터 구조 및 결측치 확인
```

**참고:** Pandas의 대부분 기술 통계 함수는 기본적으로 결측치(`NaN`)를 제외하고 계산합니다. 이는 `skipna=True` (기본값) 설정 때문입니다.

### 2.3.1 중심 경향성 측정 (Measures of Central Tendency)

데이터의 중심 경향성은 데이터 값들이 어떤 값을 중심으로 분포하는 경향이 있는지를 나타내는 척도입니다. 대표적인 중심 경향성 측정 지표로는 평균, 중앙값, 최빈값이 있습니다.

* **(시각 자료 예시:** 정규분포 곡선 위에 평균, 중앙값, 최빈값이 일치하는 모습을 보여주고, 비대칭 분포(skewed distribution)에서 세 값이 달라지는 모습을 비교하는 그림)

* **평균 (Mean):**
    * 모든 데이터 값을 더한 후 데이터 개수로 나눈 값입니다.
    * 데이터 전체의 값을 반영하지만, 극단적인 값(이상치)에 영향을 받기 쉽습니다.
    * Pandas에서는 `.mean()` 메서드를 사용합니다.

```{python}
    # Age와 Income 열의 평균 계산
    mean_age = df_survey['Age'].mean()
    mean_income = df_survey['Income'].mean()
    mean_satisfaction = df_survey['SatisfactionScore'].mean() # NaN은 자동 제외

    print(f"평균 나이: {mean_age:.2f}")
    print(f"평균 소득: {mean_income:.2f}")
    print(f"평균 만족도 점수: {mean_satisfaction:.2f}")
```

* **중앙값 (Median):**
    * 데이터를 크기 순서대로 정렬했을 때 중앙에 위치하는 값입니다.
    * 데이터 개수가 짝수일 경우, 중앙에 위치한 두 값의 평균을 사용합니다.
    * 평균과 달리 극단적인 값(이상치)에 영향을 덜 받습니다 (Robust).
    * Pandas에서는 `.median()` 메서드를 사용합니다.

```{python}
    # Age와 Income 열의 중앙값 계산
    median_age = df_survey['Age'].median()
    median_income = df_survey['Income'].median()
    median_satisfaction = df_survey['SatisfactionScore'].median() # NaN은 자동 제외

    print(f"나이 중앙값: {median_age}")
    print(f"소득 중앙값: {median_income}")
    print(f"만족도 점수 중앙값: {median_satisfaction}")

    # 평균과 중앙값 비교 (소득 분포가 비대칭적일 경우 차이가 발생할 수 있음)
    print(f"\n소득 - 평균: {mean_income:.2f}, 중앙값: {median_income}")
```

* **최빈값 (Mode):**
    * 데이터에서 가장 빈번하게 나타나는 값입니다.
    * 연속형 데이터보다는 범주형 데이터나 이산형 데이터에서 주로 사용됩니다.
    * 최빈값은 여러 개 존재할 수 있습니다.
    * Pandas에서는 `.mode()` 메서드를 사용합니다. `.mode()`는 최빈값이 여러 개일 경우 모든 값을 Series 형태로 반환합니다.

```{python}
    # Gender와 EducationLevel 열의 최빈값 계산
    mode_gender = df_survey['Gender'].mode()
    mode_education = df_survey['EducationLevel'].mode()
    mode_satisfaction = df_survey['SatisfactionScore'].mode() # 최빈값은 여러 개일 수 있음

    print(f"성별 최빈값:\n{mode_gender}")
    print(f"\n학력 최빈값:\n{mode_education}")
    print(f"\n만족도 점수 최빈값:\n{mode_satisfaction}") # 7점이 3번으로 가장 많음
```

| 측정 지표  | 설명                               | Pandas 메서드 | 특징                         |
| :--------- | :--------------------------------- | :------------ | :--------------------------- |
| 평균 (Mean) | 모든 값의 합 / 개수                | `.mean()`     | 이상치에 민감                |
| 중앙값 (Median) | 정렬 시 중앙에 위치하는 값       | `.median()`   | 이상치에 덜 민감 (Robust) |
| 최빈값 (Mode) | 가장 빈번하게 나타나는 값        | `.mode()`     | 범주형 데이터에 유용, 여러 개 가능 |

### 2.3.2 산포도 측정 (Measures of Dispersion)

산포도는 데이터 값들이 중심 경향성 값(주로 평균)으로부터 얼마나 흩어져 있는지를 나타내는 척도입니다. 데이터의 변동성이나 다양성을 파악하는 데 중요합니다.

* **(시각 자료 예시:** 평균은 같지만 분산(표준편차)이 다른 두 분포를 비교하는 그림. 좁고 뾰족한 분포와 넓고 평평한 분포)

* **범위 (Range):**
    * 데이터의 최댓값과 최솟값의 차이입니다.
    * 계산이 간단하지만, 양 극단의 값에만 의존하므로 데이터 전체의 흩어짐 정도를 충분히 반영하지 못할 수 있습니다.
    * Pandas에서는 `.max()`와 `.min()`을 이용하여 계산합니다.

```{python}
    # Age의 범위 계산
    range_age = df_survey['Age'].max() - df_survey['Age'].min()
    print(f"나이 범위: {range_age} (최소: {df_survey['Age'].min()}, 최대: {df_survey['Age'].max()})")
```

* **분산 (Variance) 및 표준편차 (Standard Deviation):**
    * **분산:** 각 데이터 값이 평균으로부터 얼마나 떨어져 있는지(편차)를 제곱하여 평균 낸 값입니다. 데이터의 퍼짐 정도를 나타냅니다. 단위가 원래 데이터 단위의 제곱이 됩니다.
    * **표준편차:** 분산에 제곱근을 취한 값입니다. 분산과 동일하게 데이터의 퍼짐 정도를 나타내지만, 단위가 원래 데이터와 동일하여 해석이 용이합니다.
    * Pandas에서는 `.var()` (분산)와 `.std()` (표준편차) 메서드를 사용합니다. 기본적으로 표본 분산/표준편차 (n-1로 나눔, `ddof=1`)를 계산합니다.

```{python}
    # Age와 Income의 분산 및 표준편차 계산
    var_age = df_survey['Age'].var()
    std_age = df_survey['Age'].std()
    var_income = df_survey['Income'].var()
    std_income = df_survey['Income'].std()
    std_satisfaction = df_survey['SatisfactionScore'].std()

    print(f"나이 분산: {var_age:.2f}, 표준편차: {std_age:.2f}")
    print(f"소득 분산: {var_income:.2f}, 표준편차: {std_income:.2f}")
    print(f"만족도 점수 표준편차: {std_satisfaction:.2f}")
```

* **사분위수 (Quartiles) 및 사분위 범위 (Interquartile Range, IQR):**
    * **사분위수:** 데이터를 크기 순으로 정렬했을 때, 4등분하는 위치에 있는 값입니다.
        * 제1사분위수 (Q1): 하위 25% 지점의 값
        * 제2사분위수 (Q2): 50% 지점의 값 (중앙값과 동일)
        * 제3사분위수 (Q3): 하위 75% 지점의 값
    * **사분위 범위 (IQR):** 제3사분위수(Q3)와 제1사분위수(Q1)의 차이 (IQR = Q3 - Q1)입니다. 데이터의 중간 50%가 분포하는 범위이며, 이상치 탐지에도 활용됩니다 (2.2.2절 참고).
    * Pandas에서는 `.quantile()` 메서드를 사용하여 특정 분위수를 계산할 수 있습니다. (예: `df['col'].quantile(0.25)`는 Q1)

```{python}
    # Income의 사분위수 및 IQR 계산
    Q1_income = df_survey['Income'].quantile(0.25)
    Q2_income = df_survey['Income'].quantile(0.50) # 중앙값과 동일
    Q3_income = df_survey['Income'].quantile(0.75)
    IQR_income = Q3_income - Q1_income

    print(f"소득 제1사분위수 (Q1): {Q1_income}")
    print(f"소득 제2사분위수 (Q2/Median): {Q2_income}")
    print(f"소득 제3사분위수 (Q3): {Q3_income}")
    print(f"소득 사분위 범위 (IQR): {IQR_income}")
```

| 측정 지표        | 설명                                   | Pandas 메서드 / 계산           | 특징                               |
| :--------------- | :------------------------------------- | :----------------------------- | :--------------------------------- |
| 범위 (Range)     | 최댓값 - 최솟값                          | `.max()` - `.min()`            | 계산 간편, 이상치에 민감             |
| 분산 (Variance)  | 편차 제곱의 평균                       | `.var()`                       | 퍼짐 정도 측정, 단위가 제곱됨        |
| 표준편차 (Std Dev) | 분산의 제곱근                          | `.std()`                       | 퍼짐 정도 측정, 원래 단위와 동일     |
| 사분위수 (Quartile)| 데이터를 4등분하는 지점의 값            | `.quantile()`                  | 데이터 분포 위치 파악              |
| IQR              | Q3 - Q1                                | `.quantile(0.75)` - `.quantile(0.25)` | 중앙 50% 데이터 범위, 이상치 영향 적음 |

### 2.3.3 분포 형태 파악 (Understanding Distribution Shape)

기술 통계는 데이터 분포의 형태에 대한 정보도 제공합니다. 왜도와 첨도는 분포의 비대칭성과 뾰족한 정도를 나타내는 지표입니다.

* **(시각 자료 예시:** 좌측으로 치우친 분포, 우측으로 치우친 분포, 대칭 분포(정규분포)의 히스토그램과 함께 왜도 값을 보여주는 그림)
* **(시각 자료 예시:** 뾰족한 분포(첨도 > 0), 정규분포(첨도 = 0), 평평한 분포(첨도 < 0)의 히스토그램과 함께 첨도 값을 보여주는 그림)

* **왜도 (Skewness):**
    * 분포의 비대칭 정도를 나타냅니다.
    * 왜도 = 0: 좌우 대칭 (예: 정규분포)
    * 왜도 > 0: 오른쪽 꼬리가 긴 분포 (Right-skewed, Positive skew) - 평균 > 중앙값
    * 왜도 < 0: 왼쪽 꼬리가 긴 분포 (Left-skewed, Negative skew) - 평균 < 중앙값
    * Pandas에서는 `.skew()` 메서드를 사용합니다.

* **첨도 (Kurtosis):**
    * 분포의 뾰족한 정도와 꼬리 두께를 나타냅니다 (정규분포 대비).
    * 첨도 = 0: 정규분포와 유사한 뾰족함 (Mesokurtic)
    * 첨도 > 0: 정규분포보다 더 뾰족하고 꼬리가 두꺼운 분포 (Leptokurtic)
    * 첨도 < 0: 정규분포보다 더 평평하고 꼬리가 얇은 분포 (Platykurtic)
    * Pandas에서는 `.kurt()` 또는 `.kurtosis()` 메서드를 사용합니다.

```{python}
    # Age와 Income의 왜도 및 첨도 계산
    skew_age = df_survey['Age'].skew()
    kurt_age = df_survey['Age'].kurt()
    skew_income = df_survey['Income'].skew()
    kurt_income = df_survey['Income'].kurt()

    print(f"나이 왜도: {skew_age:.2f}, 첨도: {kurt_age:.2f}")
    print(f"소득 왜도: {skew_income:.2f}, 첨도: {kurt_income:.2f}")
```

    **참고:** 왜도와 첨도는 값 자체만으로 분포 형태를 단정하기 어려울 수 있으며, 히스토그램 등 시각화(2.4절에서 다룸)를 통해 함께 확인하는 것이 좋습니다.

### 2.3.4 범주형 데이터 기술 통계 (Descriptive Statistics for Categorical Data)

범주형 데이터(성별, 학력 등)는 평균이나 표준편차 같은 수치적 요약보다는 각 범주의 빈도(Frequency)나 비율(Proportion)을 파악하는 것이 중요합니다.

* **빈도표 (Frequency Table):**
    * 각 범주에 속하는 데이터의 개수(빈도)를 나타내는 표입니다.
    * Pandas에서는 `.value_counts()` 메서드를 사용하여 쉽게 생성할 수 있습니다.

```{python}
    # Gender와 EducationLevel의 빈도표 생성
    freq_gender = df_survey['Gender'].value_counts()
    freq_education = df_survey['EducationLevel'].value_counts()

    print("성별 빈도:")
    print(freq_gender)
    print("\n학력 빈도:")
    print(freq_education)
```

* **비율 (Proportions):**
    * 각 범주의 빈도를 전체 데이터 개수로 나눈 값입니다. 전체에서 각 범주가 차지하는 비중을 백분율 등으로 나타낼 수 있습니다.
    * `.value_counts(normalize=True)`를 사용하면 비율을 계산할 수 있습니다.

```{python}
    # Gender와 EducationLevel의 비율 계산
    prop_gender = df_survey['Gender'].value_counts(normalize=True)
    prop_education = df_survey['EducationLevel'].value_counts(normalize=True)

    print("성별 비율:")
    print(prop_gender)
    print("\n학력 비율:")
    print(prop_education)

    # 백분율로 표시
    print("\n학력 백분율:")
    print((prop_education * 100).round(2).astype(str) + '%')
```

| 분석 방법        | 설명                           | Pandas 메서드                     |
| :--------------- | :----------------------------- | :-------------------------------- |
| 빈도표 (Frequency) | 각 범주의 개수                 | `.value_counts()`                 |
| 비율 (Proportion)| 각 범주의 비율 (전체 대비)     | `.value_counts(normalize=True)` |

### 2.3.5 모든 변수 요약: `.describe()` 메서드 활용

Pandas의 `.describe()` 메서드는 DataFrame의 수치형 변수에 대한 주요 기술 통계량(개수, 평균, 표준편차, 최소값, 사분위수, 최댓값)을 한 번에 계산하여 보여줍니다. 이는 데이터 탐색 초기 단계에서 매우 유용합니다.

```{python}
# 수치형 변수에 대한 기술 통계 요약
numeric_summary = df_survey.describe()
print("수치형 변수 요약 통계:")
print(numeric_summary)
```

`include='all'` 옵션을 사용하면 수치형 변수뿐만 아니라 범주형 변수에 대한 요약 정보(개수, 고유값 개수, 최빈값, 최빈값 빈도)도 함께 확인할 수 있습니다.

```{python}
# 모든 변수에 대한 기술 통계 요약 (범주형 포함)
all_summary = df_survey.describe(include='all')
print("\n모든 변수 요약 통계:")
print(all_summary)
```
**참고:** `.describe(include='all')` 결과에서 수치형 변수의 'unique', 'top', 'freq'는 NaN으로 표시되고, 범주형 변수의 'mean', 'std', 'min', '25%', '50%', '75%', 'max'는 NaN으로 표시됩니다. 'count'는 모든 변수 유형에 대해 유효한 값(non-null 개수)을 보여줍니다.

### 2.3.6 기술 통계 분석의 중요성

기술 통계 분석은 복잡한 데이터를 이해하기 쉬운 형태로 요약하고, 데이터의 숨겨진 패턴이나 특징을 발견하는 첫걸음입니다. 사회과학 연구에서 연구 가설을 설정하거나, 분석 방법을 선택하거나, 분석 결과를 해석하는 데 있어 데이터의 기본적인 특성을 파악하는 것은 필수적입니다. Pandas를 활용한 기술 통계 분석은 이러한 과정을 효율적이고 체계적으로 수행할 수 있도록 돕습니다. 다음 절에서는 이러한 데이터를 시각적으로 탐색하는 방법에 대해 알아보겠습니다.

---

