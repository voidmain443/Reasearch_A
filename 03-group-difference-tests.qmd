---
title : 제3장 집단 간 평균 차이 검증

format: 
    html: 
        code-fold: false
jupyter: python3
---


## 3.1 독립표본 t-검정: 두 독립 집단의 평균 비교 {#sec-independent-t-test}

앞선 2장에서는 데이터를 준비하고 탐색하는 기본적인 기술을 익혔습니다. 이제부터는 수집된 데이터를 바탕으로 구체적인 연구 질문에 답하는 통계적 추론의 세계로 나아갑니다. 제3부에서는 여러 집단 간의 차이나 변수 간의 관계를 통계적으로 검증하는 방법들을 다룹니다.

그 첫 번째 단계로, 사회과학 연구에서 매우 빈번하게 사용되는 **독립표본 t-검정(Independent Samples t-test)**에 대해 알아봅니다. 이 검정은 서로 **독립적인 두 집단** 간에 특정 **연속형 변수의 평균**에 통계적으로 유의미한 차이가 있는지를 확인하고자 할 때 사용됩니다.

예를 들어, 다음과 같은 연구 질문에 답하기 위해 독립표본 t-검정을 사용할 수 있습니다.

* 성별(남성 vs 여성)에 따라 평균 소득에 차이가 있는가?
* 특정 정책 지지 집단과 반대 집단 간에 평균 정부 신뢰도 점수에 차이가 있는가?
* 실험 처치를 받은 집단(실험집단)과 받지 않은 집단(통제집단) 간에 평균 문제 해결 능력 점수에 차이가 있는가?

독립표본 t-검정은 관찰된 두 표본 평균 간의 차이가 단순히 우연(표본 추출 오차)에 의한 것인지, 아니면 실제 모집단에서도 의미 있는 차이가 존재한다고 볼 수 있는지 통계적으로 판단하는 근거를 제공합니다.

::: callout-note
## 📌 핵심 요약

독립표본 t-검정은 서로 독립적인 두 집단 간의 연속형 변수 평균 차이를 통계적으로 검증하는 방법입니다. 이 절에서는 t-검정의 기본 원리(가설 설정, t-통계량, p-값), 주요 가정(독립성, 정규성, 등분산성), 파이썬 `scipy.stats` 라이브러리를 이용한 구현 방법, 가정 검토(Shapiro-Wilk, Levene 검정), Welch's t-검정의 활용, 결과 해석, 효과 크기(Cohen's d) 계산 및 해석, 그리고 결과 보고 방법까지 학습합니다.
:::

### 3.1.1 독립표본 t-검정의 원리: 가설 설정과 검정 통계량

독립표본 t-검정은 가설 검증의 틀 안에서 이루어집니다.

* **가설 설정:**
    * **귀무가설 (Null Hypothesis, $H_0$):** 두 집단의 모집단 평균은 같다 ($H_0: \mu_1 = \mu_2$ 또는 $H_0: \mu_1 - \mu_2 = 0$). 즉, 우리가 표본에서 관찰한 평균 차이는 우연에 의한 것이다.
    * **대립가설 (Alternative Hypothesis, $H_1$):** 두 집단의 모집단 평균은 다르다 ($H_1: \mu_1 \neq \mu_2$). 이 가설은 연구자가 입증하고자 하는 내용으로, 표본 평균 차이가 우연이라고 보기에는 너무 크다는 것을 의미합니다. 이는 **양측 검정(Two-tailed test)**에 해당합니다.
        * 만약 연구자가 특정 방향의 차이(예: 집단 1이 집단 2보다 평균이 클 것이다)를 예측한다면 단측 검정($H_1: \mu_1 > \mu_2$ 또는 $H_1: \mu_1 < \mu_2$)을 설정할 수도 있지만, 특별한 근거가 없다면 일반적으로 양측 검정을 사용합니다.

* **검정 통계량 (Test Statistic, t-value):**
    * t-검정은 두 표본 평균 간의 차이를 표준 오차(Standard Error)로 나눈 값인 **t-통계량**을 계산합니다. 이는 관찰된 평균 차이가 그룹 내 변동성(오차)에 비해 얼마나 큰지를 나타내는 표준화된 값입니다.
    * 개념적으로 t-값은 다음과 같이 표현될 수 있습니다:
        $t = \frac{(\text{두 표본 평균의 차이}) - (\text{귀무가설 하에서의 평균 차이, 보통 0})}{(\text{두 평균 차이의 표준 오차})}$
        $t = \frac{(\bar{x}_1 - \bar{x}_2)}{SE_{(\bar{x}_1 - \bar{x}_2)}}$
    * t-값의 절댓값이 클수록 두 집단 간 평균 차이가 우연히 발생했을 가능성이 작아집니다.

* **p-값 (p-value):**
    * p-값은 **귀무가설($H_0$)이 참이라고 가정할 때**, 우리가 표본에서 계산한 t-통계량 값 또는 그보다 더 극단적인 값이 관찰될 확률입니다.
    * p-값이 매우 작다(예: 0.05 미만)는 것은, 귀무가설이 맞다면 현재와 같은 표본 결과가 나타나기 매우 어렵다는 것을 의미합니다.

* **의사 결정:**
    * 미리 설정한 **유의수준(Significance level, $\alpha$)**과 p-값을 비교하여 귀무가설 기각 여부를 결정합니다. 사회과학에서는 보통 $\alpha = 0.05$ (5%)를 사용합니다.
    * **p-값 < $\alpha$ :** 귀무가설($H_0$)을 기각하고 대립가설($H_1$)을 채택합니다. 즉, 두 집단 간 평균에 통계적으로 유의미한 차이가 있다고 결론 내립니다.
    * **p-값 $\ge$ $\alpha$ :** 귀무가설($H_0$)을 기각하지 못합니다(채택하는 것이 아님). 즉, 두 집단 간 평균 차이가 통계적으로 유의미하다는 충분한 근거를 찾지 못했다고 결론 내립니다.

### 3.1.2 독립표본 t-검정의 가정

독립표본 t-검정 결과를 신뢰하기 위해서는 몇 가지 가정이 충족되어야 합니다.

1.  **독립성 (Independence of Observations):** 한 집단 내의 관측치들은 서로 독립적이어야 하며, 두 집단 간의 관측치들도 서로 독립적이어야 합니다. 이는 주로 연구 설계 및 표본 추출 방법과 관련됩니다. (예: 무작위 할당, 무작위 표본 추출)
2.  **정규성 (Normality):** 종속변수는 **각 집단별로** 정규분포를 따라야 합니다.
    * **확인 방법:** 각 집단별 히스토그램, Q-Q 플롯 확인(2.4절), 또는 정규성 검정(예: Shapiro-Wilk test) 수행.
    * **견고성(Robustness):** 표본 크기가 충분히 크면(예: 각 집단별 30 이상), 중심극한정리(Central Limit Theorem)에 의해 t-검정은 정규성 가정 위반에 비교적 덜 민감합니다.
3.  **등분산성 (Homogeneity of Variances, Homoscedasticity):** 두 집단의 모집단 분산이 동일해야 합니다.
    * **확인 방법:** Levene의 등분산 검정(Levene's test) 수행.
    * **중요성:** 전통적인 Student's t-test는 이 가정을 요구하지만, 이 가정이 충족되지 않을 때 사용할 수 있는 **Welch's t-test**가 있습니다. Welch's t-test는 등분산성 가정을 요구하지 않으며, 등분산성이 충족될 때에도 Student's t-test와 유사한 결과를 제공하므로, **많은 경우 Welch's t-test를 기본으로 사용하는 것이 권장됩니다.**

### 3.1.3 파이썬을 이용한 독립표본 t-검정 (`scipy.stats`)

파이썬의 `scipy.stats` 모듈은 독립표본 t-검정을 수행하는 `ttest_ind` 함수를 제공합니다. 2.5절에서 사용한 `df_practice` 데이터를 이용하여 성별(`Gender`)에 따른 소득(`Income`) 평균 차이가 있는지 검정해 보겠습니다.

**1. 데이터 준비:**
먼저, 비교할 두 집단(남성, 여성)의 `Income` 데이터를 각각 추출합니다.



```{python}
import pandas as pd
import numpy as np
from scipy import stats # t-test 및 관련 검정 함수 포함
import matplotlib.pyplot as plt # 가정 검토 시각화용 (선택적)
import seaborn as sns # 가정 검토 시각화용 (선택적)

# CSV 파일로부터 데이터 불러오기
# 파일 경로는 실제 파일 위치에 맞게 수정해야 합니다.
try:
    # csv_filepath = 'path/to/your/data_process.csv' # 실제 파일 경로로 수정
    csv_filepath = 'data_process.csv' # 2.5절에서 저장한 파일과 동일 디렉토리에 있다고 가정
    df_processed = pd.read_csv(csv_filepath, index_col=0) # index_col=0 추가

    print("데이터 불러오기 성공!")
    print("\n--- 불러온 데이터 확인 (처음 5행) ---")
    print(df_processed.head())

    # 데이터 타입 확인 (CSV 로딩 후 타입 변경 가능성 있음)
    print("\n--- 불러온 데이터 정보 확인 ---")
    df_processed.info()

    # Education 변수 순서형 범주 타입 재지정 (필요시)
    if not pd.api.types.is_categorical_dtype(df_processed['Education']) or not df_processed['Education'].cat.ordered:
        print("\nEducation 변수 타입을 순서형 범주(Ordered Categorical)로 재지정합니다.")
        edu_order = ['High School', 'Bachelor', 'Master', 'PhD']
        df_processed['Education'] = pd.Categorical(df_processed['Education'], categories=edu_order, ordered=True)
        df_processed.info() # 타입 변경 확인

except FileNotFoundError:
    print(f"오류: '{csv_filepath}' 파일을 찾을 수 없습니다.")
    print("2.5절에서 'data_process.csv' 파일이 정상적으로 저장되었는지, 파일 경로가 올바른지 확인해주세요.")
    # 예제 진행을 위해 중단 (실제 사용 시에는 파일 로딩 필수)
    raise # 오류 발생시키고 중단

# 성별에 따른 Income 데이터 분리 (이제 df_processed 사용)
male_income = df_processed[df_processed['Gender'] == 'Male']['Income']
female_income = df_processed[df_processed['Gender'] == 'Female']['Income']

print(f"\nMale Income 데이터 개수: {len(male_income)}")
print(f"Female Income 데이터 개수: {len(female_income)}")
```

**2. 가정 검토 (선택적이지만 권장):**

* **정규성 검토 (Shapiro-Wilk Test):** 각 집단의 `Income` 데이터가 정규분포를 따르는지 확인합니다. 귀무가설($H_0$)은 '데이터가 정규분포를 따른다'입니다.

```{python}
    # 남성 Income 정규성 검정
    shapiro_male = stats.shapiro(male_income)
    print(f"Shapiro-Wilk Test (Male Income): Statistic={shapiro_male.statistic:.3f}, p-value={shapiro_male.pvalue:.3f}")

    # 여성 Income 정규성 검정
    shapiro_female = stats.shapiro(female_income)
    print(f"Shapiro-Wilk Test (Female Income): Statistic={shapiro_female.statistic:.3f}, p-value={shapiro_female.pvalue:.3f}")
```
    * **해석:** 만약 p-값이 유의수준(예: 0.05)보다 크면, 정규분포를 따른다는 귀무가설을 기각할 수 없으므로 정규성 가정을 만족한다고 볼 수 있습니다. 만약 p-값이 0.05보다 작으면 정규성 가정이 위배될 수 있으나, 표본 크기가 충분히 크다면(예: 각 그룹 30 이상) t-검정은 여전히 사용 가능할 수 있습니다. 시각적 확인(히스토그램, Q-Q 플롯)을 병행하는 것이 좋습니다.

* **등분산성 검토 (Levene's Test):** 두 집단의 분산이 동일한지 확인합니다. 귀무가설($H_0$)은 '두 집단의 분산은 같다'입니다.

```{python}
    # 등분산성 검정 (Levene's Test)
    levene_test = stats.levene(male_income, female_income)
    print(f"\nLevene's Test for Equal Variances: Statistic={levene_test.statistic:.3f}, p-value={levene_test.pvalue:.3f}")
```
    * **해석:** 만약 p-값이 유의수준(예: 0.05)보다 크면, 등분산성 가정을 만족한다고 볼 수 있습니다 (`equal_var=True` 사용 가능). 만약 p-값이 0.05보다 작으면 등분산성 가정이 위배되므로 `equal_var=False` (Welch's t-test)를 사용해야 합니다.

**3. t-검정 수행:**

`scipy.stats.ttest_ind()` 함수를 사용합니다. `equal_var` 파라미터 설정이 중요합니다. Levene 검정 결과와 관계없이, 일반적으로 **`equal_var=False` (Welch's t-test)를 사용하는 것이 더 안전하고 권장됩니다.**

```{python}
# 독립표본 t-검정 수행 (Welch's t-test 권장)
# Levene 검정 p-값이 0.05보다 크더라도 Welch's 사용 가능
t_statistic, p_value = stats.ttest_ind(male_income, female_income, equal_var=False) # Welch's t-test

print(f"\n--- Independent Samples t-test (Welch's) Results ---")
print(f"T-statistic: {t_statistic:.3f}")
print(f"P-value: {p_value:.3f}")

# 참고: 만약 등분산성 가정이 충족되고 Student's t-test를 원한다면:
# t_stat_student, p_val_student = stats.ttest_ind(male_income, female_income, equal_var=True)
# print("\n--- Student's t-test Results (if assumptions met) ---")
# print(f"T-statistic: {t_stat_student:.3f}, P-value: {p_val_student:.3f}")
```

**4. 결과 해석:**

계산된 t-통계량과 p-값을 바탕으로 결론을 내립니다. 유의수준 $\alpha = 0.05$를 기준으로 판단합니다.

* **해석 (예시 결과 기반):** 만약 위 코드 실행 결과 `p_value`가 0.05보다 작게 나왔다면 (예: `p_value = 0.021`), 다음과 같이 해석합니다.
    * "독립표본 t-검정(Welch's) 결과, 성별에 따른 평균 소득에는 통계적으로 유의미한 차이가 있는 것으로 나타났다 (t = [t-값], p = 0.021). 유의수준 0.05에서 귀무가설('남성과 여성의 평균 소득은 같다')을 기각한다."
* 만약 `p_value`가 0.05보다 크거나 같게 나왔다면 (예: `p_value = 0.350`), 다음과 같이 해석합니다.
    * "독립표본 t-검정(Welch's) 결과, 성별에 따른 평균 소득 차이는 통계적으로 유의미하지 않았다 (t = [t-값], p = 0.350). 유의수준 0.05에서 귀무가설('남성과 여성의 평균 소득은 같다')을 기각할 충분한 근거를 찾지 못했다."

**중요:** 통계적 유의성은 '차이가 존재한다/하지 않는다'는 증거의 강도를 말해줄 뿐, 그 차이가 **실질적으로 얼마나 크고 중요한지**는 별도로 평가해야 합니다. 이를 위해 **효과 크기(Effect Size)**를 확인합니다.

### 3.1.4 효과 크기 계산 및 해석 (Cohen's d)

효과 크기는 두 집단 간 평균 차이의 **크기(magnitude)**를 나타내는 표준화된 지표입니다. 표본 크기에 영향을 덜 받으며, 결과의 실질적인 중요성을 평가하는 데 도움을 줍니다. t-검정에서는 **Cohen's d**가 널리 사용됩니다.

* **Cohen's d 정의:** 두 집단 평균의 차이를 합동 표준편차(pooled standard deviation)로 나눈 값입니다.
    $d = \frac{|\bar{x}_1 - \bar{x}_2|}{s_p}$
    (여기서 $s_p$는 두 집단의 표준편차를 고려한 합동 표준편차입니다. Welch's t-test의 경우 약간 다른 방식으로 계산될 수 있으나, 개념은 유사합니다.)

* **Cohen's d 해석 기준 (일반적 가이드라인):**
    * $|d| \approx 0.2$: 작은 효과 크기
    * $|d| \approx 0.5$: 중간 효과 크기
    * $|d| \approx 0.8$: 큰 효과 크기

* **파이썬으로 Cohen's d 계산 (수동 계산 예시):**

```{python}
    # Cohen's d 계산 함수 (Welch's t-test에 근사)
    def cohens_d(group1, group2):
        # 그룹별 평균, 표준편차, 샘플 사이즈
        mean1, mean2 = np.mean(group1), np.mean(group2)
        std1, std2 = np.std(group1, ddof=1), np.std(group2, ddof=1) # ddof=1 for sample std dev
        n1, n2 = len(group1), len(group2)

        # 합동 표준편차 (Welch's t-test는 분산이 다르다고 가정하므로, 약간의 근사 사용)
        # 간단하게는 전체 샘플의 표준편차 또는 더 복잡한 공식을 사용할 수 있으나, 여기서는 근사치로 계산
        # (정확한 Welch's d 계산은 복잡할 수 있음)
        # 평균 표준편차 사용 (간단한 근사)
        # pooled_std = np.sqrt((std1**2 + std2**2) / 2)
        # 또는 더 일반적인 합동 표준편차 (등분산 가정 시)
        pooled_std = np.sqrt(((n1 - 1) * std1**2 + (n2 - 1) * std2**2) / (n1 + n2 - 2))

        d = (mean1 - mean2) / pooled_std
        return abs(d) # 효과 크기는 보통 절댓값으로 표현

    # Income by Gender Cohen's d 계산
    d_income_gender = cohens_d(male_income, female_income)
    print(f"\nCohen's d for Income difference between Genders: {d_income_gender:.3f}")

    # 해석 (예시)
    if d_income_gender < 0.2:
      effect_size_interpretation = "매우 작음 (trivial)"
    elif d_income_gender < 0.5:
      effect_size_interpretation = "작음 (small)"
    elif d_income_gender < 0.8:
      effect_size_interpretation = "중간 (medium)"
    else:
      effect_size_interpretation = "큼 (large)"

    print(f"효과 크기 해석: {effect_size_interpretation}")
```
    **참고:** `pingouin`과 같은 다른 통계 라이브러리는 `pg.ttest()` 함수 내에서 Cohen's d를 직접 계산해주는 기능을 제공하기도 합니다.

### 3.1.5 결과 보고

t-검정 결과를 논문이나 보고서에 제시할 때는 다음과 같은 정보들을 포함하는 것이 일반적입니다 (APA 스타일 등 참고).

1.  비교 대상인 두 집단.
2.  비교 대상인 종속변수.
3.  각 집단의 평균(M)과 표준편차(SD).
4.  사용한 t-검정의 종류 (예: 독립표본 t-검정, Welch's t-검정).
5.  t-통계량 값과 자유도(degree of freedom, df). `scipy.stats.ttest_ind`는 Welch's t-test의 경우 정확한 자유도를 반환하지 않지만, 다른 라이브러리나 수동 계산을 통해 얻을 수 있습니다. 여기서는 생략하거나 t-값만 제시할 수 있습니다. (참고: `pingouin` 라이브러리는 df를 제공합니다.)
6.  p-값 (정확한 값 또는 < .05, < .01 등으로 표기).
7.  효과 크기 (예: Cohen's d).

* **보고 예시 (위 예시 결과가 유의미했다고 가정):**
    "성별에 따른 평균 소득 차이를 분석하기 위해 독립표본 t-검정(Welch's)을 실시하였다. 분석 결과, 남성 집단(M = [남성평균], SD = [남성표준편차])의 평균 소득이 여성 집단(M = [여성평균], SD = [여성표준편차])보다 통계적으로 유의미하게 높은 것으로 나타났다 (t ≈ [t-값], p = [p-값]). 이 차이의 효과 크기는 Cohen's d = [d-값]로, [작은/중간/큰] 수준의 효과에 해당한다."

### 3.1.6 요약 및 다음 단계

이번 절에서는 서로 독립적인 두 집단 간의 평균 차이를 검증하는 강력한 도구인 독립표본 t-검정에 대해 배웠습니다. 가설 설정부터 파이썬 코드 구현, 가정 검토, 결과 해석, 효과 크기 계산, 그리고 결과 보고 방법까지 전 과정을 살펴보았습니다.

**핵심 사항:**

* 독립표본 t-검정은 **두 독립 집단**의 **연속형 변수 평균** 비교에 사용됩니다.
* **가정(독립성, 정규성, 등분산성)**을 확인하는 것이 중요하며, 특히 등분산성 가정이 충족되지 않을 경우 **Welch's t-test (`equal_var=False`)** 사용이 권장됩니다.
* **p-값**은 통계적 유의성을 판단하는 기준이며, **효과 크기(Cohen's d)**는 차이의 실제적인 크기를 나타냅니다. 두 가지 모두 해석에 중요합니다.

**한계점:** 독립표본 t-검정은 비교 집단이 **두 개**일 경우에만 사용할 수 있습니다. 또한, 평균 비교 외에 다른 정보(예: 분포 형태)는 고려하지 않습니다.

다음 절(3.2)에서는 **동일한 집단**에서 얻어진 두 측정값(예: 사전-사후 점수)의 평균 차이를 비교하는 **대응표본 t-검정(Paired Samples t-test)**에 대해 알아보겠습니다.



